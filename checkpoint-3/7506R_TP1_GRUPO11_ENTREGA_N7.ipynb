{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Trabajo Práctico 1: Propiedades en Venta - Gradient Boost\n",
        "\n",
        "## Grupo 11 - \"Los Outliers\"\n",
        "- Castillo, Carlos\n",
        "- Destefanis, Juan Pablo\n",
        "- Gómez, Celeste"
      ],
      "metadata": {
        "id": "QDP2HunyQWws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries"
      ],
      "metadata": {
        "id": "7vtIUiHnVs_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "P9Zg_G2KVxJV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load del DataFrame a utilizar\n",
        "\n",
        "Cargo los datos con los avisos clasificados con su tipo de precio. También fijamos una semilla para usarla a lo largo de toda la notebook."
      ],
      "metadata": {
        "id": "DLBbZuOlVm-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://drive.google.com/uc?id=1GhsJwy29gS2y_HibaDeChkx-ozSc2Qc3\", index_col=0)\n",
        "semilla = 137"
      ],
      "metadata": {
        "id": "7N5oCJmQVoXS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Limpieza de los datos\n",
        "\n",
        "Lo primero que hacemos para poder entrenar el modelo de Gradient Boost es seleccionar las columnas del dataframe que consideramos más relevantes. Hay algunas, como el `id` y  `property_title`, que claramente no aportan información útil. También, removemos la columna de `property_price` por ser el target, y las columnas de `precio_m2` y `tipo_precio` por estar íntimamente relacionadas. Finalmente, usamos un *label encoder* para las columnas `neighbourhood` y `property_type`, que necesitan ser numéricas para que las pueda considerar el modelo. Dado que queremos evitar tener muchas columnas, optamos por no usar One Hot Encoding."
      ],
      "metadata": {
        "id": "Vz1S2xQ2XM4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "df_features = df[[\n",
        "    \"latitud\",\n",
        "    \"longitud\",\n",
        "    \"neighbourhood\",\n",
        "    \"property_type\",\n",
        "    \"property_rooms\",\n",
        "    \"property_bedrooms\",\n",
        "    \"property_surface_total\",\n",
        "    \"property_surface_covered\"]]\n",
        "\n",
        "df_target = df[[\"property_price\"]]\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "df_features.loc[:, 'property_type'] = encoder.fit_transform(df_features.property_type.values)\n",
        "df_features.loc[:, 'neighbourhood'] = encoder.fit_transform(df_features.neighbourhood.values)"
      ],
      "metadata": {
        "id": "Lhde7nraV221"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego, genero los conjuntos de train y test."
      ],
      "metadata": {
        "id": "VH3Le0CFaFkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_features, df_target.values.ravel(), test_size=0.20, random_state=semilla)"
      ],
      "metadata": {
        "id": "eyUNRTepZ8nv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento de un primer modelo"
      ],
      "metadata": {
        "id": "j3hoUN1Jd2e4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Empezamos entrenando un modelo base, para luego entrenar otro optimizando sus hiperparámetros y poder compararlos."
      ],
      "metadata": {
        "id": "_5pbDG1rd9Na"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import ensemble\n",
        "\n",
        "regressor = ensemble.GradientBoostingRegressor(random_state=semilla)\n",
        "regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "JOZ4XcM5d0Y7",
        "outputId": "0eec651f-ce45-43e4-9666-1540295968b4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(random_state=137)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(random_state=137)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(random_state=137)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observo las métricas del modelo en testing y en training."
      ],
      "metadata": {
        "id": "fyz7IhsnlvG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "prediccion_train = regressor.predict(X_train)\n",
        "mse = mean_squared_error(y_train, prediccion_train)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_train, prediccion_train)\n",
        "\n",
        "print(\"\\nMétricas con el conjunto de training.\\n\")\n",
        "print(\"RMSE (train): {:.4f}\".format(rmse))\n",
        "print(\"MSE (train): {:.4f}\".format(mse))\n",
        "print(\"R2 (train): {:.4f}\".format(r2))\n",
        "\n",
        "prediccion_test = regressor.predict(X_test)\n",
        "mse = mean_squared_error(y_test, prediccion_test)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, prediccion_test)\n",
        "\n",
        "print(\"\\nMétricas con el conjunto de testing.\\n\")\n",
        "print(\"RMSE (test): {:.4f}\".format(rmse))\n",
        "print(\"MSE (test): {:.4f}\".format(mse))\n",
        "print(\"R2 (test): {:.4f}\".format(r2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9olcEVxiP7U",
        "outputId": "9f7c1788-b766-4f9d-989d-c70487656c5a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Métricas con el conjunto de training.\n",
            "\n",
            "RMSE (train): 58088.2673\n",
            "MSE (train): 3374246792.6480\n",
            "R2 (train): 0.8096\n",
            "\n",
            "Métricas con el conjunto de testing.\n",
            "\n",
            "RMSE (test): 59288.4529\n",
            "MSE (test): 3515120646.7748\n",
            "R2 (test): 0.8008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Randomized Search"
      ],
      "metadata": {
        "id": "122XcCefbGng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez entrenado un modelo base para poder comparar luego, buscamos entrenar un nuevo modelo optimizando los siguientes hiperparámetros:\n",
        "\n",
        "* `n_stimators`: Cantidad de árboles máximos que pueden estar presentes en el modelo.\n",
        "* `max_depth`: Máximo nivel de profundidad que puede tener cada árbol.\n",
        "* `learning_rate`: Valor utilizado para disminuir que tanto contribuye cada árbol al resultado final.\n",
        "* `loss`: Función de perdida a optimizar. Vamos a probar con el error cuadrático, el error absoluto y \"huber\", que es una combinación de ambos.\n"
      ],
      "metadata": {
        "id": "s4vnTZ66uBQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params_grid = {\n",
        "    \"n_estimators\": range(20, 50),\n",
        "    \"max_depth\": [8, 16, 24, 32],\n",
        "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
        "    \"loss\": [\"squared_error\", \"absolute_error\"],\n",
        "}"
      ],
      "metadata": {
        "id": "qEMvCPOjb1XI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "De manera similar a como lo hicimos en la parte de clasificación, usamos Stratified KFold porque hay una distribución dispareja en las categorías del target que queremos tratar de mantener en cada fold. También, elegimos usar 5 folds.\n",
        "\n",
        "Por otro lado, y también como lo hicimos en la etapa de clasificación, utilizamos RandomizedSearch en lugar de GridSearch para ahorrar tiempo mientras experimentamos."
      ],
      "metadata": {
        "id": "EF2PH5uEbH3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
        "\n",
        "folds=5\n",
        "kfoldcv = StratifiedKFold(n_splits=folds, shuffle=True, random_state=semilla)\n",
        "\n",
        "base_regressor = ensemble.GradientBoostingRegressor(random_state=semilla)\n",
        "\n",
        "randomcv = RandomizedSearchCV(\n",
        "    estimator=base_regressor,\n",
        "    scoring=\"r2\",\n",
        "    param_distributions=params_grid,\n",
        "    n_iter=10,\n",
        "    cv=kfoldcv,\n",
        "    random_state=semilla,\n",
        "    verbose=2\n",
        ")"
      ],
      "metadata": {
        "id": "AgZkbXD0dEI1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para entrenar al modelo utilizamos el método fit con el set de entrenamiento ya transformado:\n",
        "\n",
        "```python\n",
        "randomcv.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "Sin embargo, luego de haber ejecutado este método con anterioridad, ya contamos con el modelo más óptimo encontrado, que ha sido exportado en un archivo de joblib, lo que nos permite simplemente cargar el archivo y no tener que volver a entrenar todos los modelos con todos los parámetros que probamos."
      ],
      "metadata": {
        "id": "Qycbb4o-e-oL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import load\n",
        "\n",
        "best_regressor = load(\"gradient_boost.joblib\")\n",
        "best_regressor.get_params()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RL1iVAdMqM1x",
        "outputId": "ebf158fa-1c5f-49ca-e8a9-359f34119db0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 0.9,\n",
              " 'ccp_alpha': 0.0,\n",
              " 'criterion': 'friedman_mse',\n",
              " 'init': None,\n",
              " 'learning_rate': 0.2,\n",
              " 'loss': 'absolute_error',\n",
              " 'max_depth': 32,\n",
              " 'max_features': None,\n",
              " 'max_leaf_nodes': None,\n",
              " 'min_impurity_decrease': 0.0,\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 2,\n",
              " 'min_weight_fraction_leaf': 0.0,\n",
              " 'n_estimators': 41,\n",
              " 'n_iter_no_change': None,\n",
              " 'random_state': 137,\n",
              " 'subsample': 1.0,\n",
              " 'tol': 0.0001,\n",
              " 'validation_fraction': 0.1,\n",
              " 'verbose': 0,\n",
              " 'warm_start': False}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente observamos las estadísticas del modelo."
      ],
      "metadata": {
        "id": "yg8YbWDiryf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediccion_train = best_regressor.predict(X_train)\n",
        "mse = mean_squared_error(y_train, prediccion_train)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_train, prediccion_train)\n",
        "\n",
        "print(\"\\nMétricas con el conjunto de training.\\n\")\n",
        "print(\"RMSE (train): {:.4f}\".format(rmse))\n",
        "print(\"MSE (train): {:.4f}\".format(mse))\n",
        "print(\"R2 (train): {:.4f}\".format(r2))\n",
        "\n",
        "prediccion_test = best_regressor.predict(X_test)\n",
        "mse = mean_squared_error(y_test, prediccion_test)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, prediccion_test)\n",
        "\n",
        "print(\"\\nMétricas con el conjunto de testing.\\n\")\n",
        "print(\"RMSE (test): {:.4f}\".format(rmse))\n",
        "print(\"MSE (test): {:.4f}\".format(mse))\n",
        "print(\"R2 (test): {:.4f}\".format(r2))"
      ],
      "metadata": {
        "id": "AlSv1FPZsozj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c910d14-3d78-4b19-b4fc-fe8a33ad2b22"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Métricas con el conjunto de training.\n",
            "\n",
            "RMSE (train): 16285.7942\n",
            "MSE (train): 265227094.1160\n",
            "R2 (train): 0.9850\n",
            "\n",
            "Métricas con el conjunto de testing.\n",
            "\n",
            "RMSE (test): 43400.0987\n",
            "MSE (test): 1883568568.2602\n",
            "R2 (test): 0.8933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si comparamos el rendimiento de este modelo con el que utilizaba los parámetros por defecto, notamos que aunque el anterior ya tenía un rendimiento significativamente positivo, este lo mejora aún más. Por el resultado de las métricas en el conjunto de training, especialmente $R^2$, podríamos sospechar que el modelo tiene overfitting, sin embargo, también muestra un desempeño robusto en el conjunto de test ante datos que nunca ha visto."
      ],
      "metadata": {
        "id": "EicLshI4r9z0"
      }
    }
  ]
}