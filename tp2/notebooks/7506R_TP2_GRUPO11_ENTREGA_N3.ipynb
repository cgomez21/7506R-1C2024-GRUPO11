{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zo3CcYgRLz6d"
   },
   "source": [
    "# Trabajo Práctico 2: Reseñas de Películas - Random Forest\n",
    "\n",
    "## Grupo 11 - \"Los Outliers\"\n",
    "\n",
    "- Castillo, Carlos\n",
    "- Destefanis, Juan Pablo\n",
    "- Gómez, Celeste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VrhPm3ScLdYK"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2iEcxo6wdds5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "652abm3QMRH7"
   },
   "source": [
    " # Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bM9iNWgBMbzn"
   },
   "source": [
    "Carga del dataset de entrenamiento anteriormente preprocesado. En este caso, a diferencia de lo que pasó con la red neuronal y XGBoost, obtuvimos mejores resultados con el dataset con preprocesamiento más complejo. Probamos con diferentes combiaciones de las diferentes columnas de este dataset, entre la cuales se encuentran dos variantes del texto preprocesado: `text_cleaned` y `text_cleaned_pos`, que son versiones del texto de la crítica a las que se le aplicó lematización, detección de stop words, regex, unidecode y manejo de las negaciones, sin embargo la diferencia es que la segunda de estas columnas incluye detección de part-of-speech, que nos permite distinguir aún más las palabras debido a su contexto de uso. Además cuenta con columnas que cuentan la cantidad de negaciones en cada crítica, la cantidad de adjetivos negativos y la cantidad de signos de exclamación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "id": "QP5gIoUXdffn",
    "outputId": "b05a7807-e639-4273-b133-65577b150365"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_es</th>\n",
       "      <th>lang</th>\n",
       "      <th>sentimiento</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>text_cleaned_pos</th>\n",
       "      <th>num_neg</th>\n",
       "      <th>num_adj_neg</th>\n",
       "      <th>num_exclm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uno de los otros críticos ha mencionado que de...</td>\n",
       "      <td>es</td>\n",
       "      <td>positivo</td>\n",
       "      <td>critico mencionar oz episodio estar enganchado...</td>\n",
       "      <td>critico_NOUN mencionar_VERB oz_DET episodio_NO...</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Una pequeña pequeña producción.La técnica de f...</td>\n",
       "      <td>es</td>\n",
       "      <td>positivo</td>\n",
       "      <td>pequén pequén produccion tecnica filmacion inc...</td>\n",
       "      <td>pequén_ADJ pequén_ADJ produccion_PROPN tecnica...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pensé que esta era una manera maravillosa de p...</td>\n",
       "      <td>es</td>\n",
       "      <td>positivo</td>\n",
       "      <td>pense maravilloso pasar tiempo semana verano c...</td>\n",
       "      <td>pense_VERB maravilloso_ADJ pasar_VERB tiempo_N...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Básicamente, hay una familia donde un niño peq...</td>\n",
       "      <td>es</td>\n",
       "      <td>negativo</td>\n",
       "      <td>basicamente familia nino pequeno jake pensar z...</td>\n",
       "      <td>basicamente_ADV familia_NOUN nino_NOUN pequeno...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>El \"amor en el tiempo\" de Petter Mattei es una...</td>\n",
       "      <td>es</td>\n",
       "      <td>positivo</td>\n",
       "      <td>amor tiempo petter_mattei pelicula visualmente...</td>\n",
       "      <td>amor_NOUN tiempo_NOUN pelicula_NOUN visualment...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            review_es lang sentimiento  \\\n",
       "ID                                                                       \n",
       "0   Uno de los otros críticos ha mencionado que de...   es    positivo   \n",
       "1   Una pequeña pequeña producción.La técnica de f...   es    positivo   \n",
       "2   Pensé que esta era una manera maravillosa de p...   es    positivo   \n",
       "3   Básicamente, hay una familia donde un niño peq...   es    negativo   \n",
       "4   El \"amor en el tiempo\" de Petter Mattei es una...   es    positivo   \n",
       "\n",
       "                                         text_cleaned  \\\n",
       "ID                                                      \n",
       "0   critico mencionar oz episodio estar enganchado...   \n",
       "1   pequén pequén produccion tecnica filmacion inc...   \n",
       "2   pense maravilloso pasar tiempo semana verano c...   \n",
       "3   basicamente familia nino pequeno jake pensar z...   \n",
       "4   amor tiempo petter_mattei pelicula visualmente...   \n",
       "\n",
       "                                     text_cleaned_pos  num_neg  num_adj_neg  \\\n",
       "ID                                                                            \n",
       "0   critico_NOUN mencionar_VERB oz_DET episodio_NO...        7            4   \n",
       "1   pequén_ADJ pequén_ADJ produccion_PROPN tecnica...        2            0   \n",
       "2   pense_VERB maravilloso_ADJ pasar_VERB tiempo_N...        2            0   \n",
       "3   basicamente_ADV familia_NOUN nino_NOUN pequeno...        0            0   \n",
       "4   amor_NOUN tiempo_NOUN pelicula_NOUN visualment...        1            2   \n",
       "\n",
       "    num_exclm  \n",
       "ID             \n",
       "0           0  \n",
       "1           2  \n",
       "2           1  \n",
       "3           4  \n",
       "4           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../datasets/train-random-forest.zip\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tBji25r3R2gA"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature_cols = [\"text_cleaned_pos\", \"num_neg\", \"num_adj_neg\", \"num_exclm\"]\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df[\"sentimiento\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, stratify=y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso obtuvimos mejores resultados utilizando ngramas de un rango de 1 a 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1GCIsLJmQy1V"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 2), strip_accents=\"unicode\", min_df=20, max_df=0.9)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tfidf\", tfidf, feature_cols[0]),\n",
    "        (\"scaler\", scaler, feature_cols[1:]),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nxoly3N8Rkqb"
   },
   "outputs": [],
   "source": [
    "X_train_trans = ct.fit_transform(X_train)\n",
    "X_val_trans = ct.transform(X_val)\n",
    "X_test_trans = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bILe91ifNCnR"
   },
   "source": [
    "# Entrenamiento del modelo\n",
    "\n",
    "Los parámetros fueron en primera instancia buscados con RandomizedSearchCV, obteniendo un modelo con mucho overfitting. Con lo cual, se optó por modificar algunos de los parámetros manualmente para reducir ese overfit. Finalmente la mejor combinación a la que llegamos fue la siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T5j2S9gO-W7j"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=4000,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=40,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=16,\n",
    "    oob_score=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train_trans, y_train)\n",
    "\n",
    "y_pred_train = rf.predict(X_train_trans)\n",
    "y_pred_val = rf.predict(X_val_trans)\n",
    "\n",
    "X_test_trans = ct.transform(X_test)\n",
    "y_pred_test = rf.predict(X_test_trans)\n",
    "\n",
    "f1_score_train = f1_score(y_train, y_pred_train, average=\"micro\")\n",
    "f1_score_val = f1_score(y_val, y_pred_val, average=\"micro\")\n",
    "f1_score_test = f1_score(y_test, y_pred_test, average=\"micro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quizá el hyperparámetro que más llama la atención es la gran cantidad de estimadores que utiliza el random forest. Terminamos llegando a valores tan elevados de este parámetro ya que al ir ajustando los parámetros para evitar el overfitting, también iba decreciendo la capacidad del modelo para obtener información de los datos, por lo que todos los parámetros de regularización terminan requiriendo que se incremente la cantidad de árboles en el forest para poder lograr un balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7YYKnqOvV0cx",
    "outputId": "13178bab-f9fe-43d7-fe10-1ef92586f466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train      - 0.8622\n",
      "validation - 0.8339 - (3.28% de diferencia con train)\n",
      "test       - 0.8311 - (3.602% de diferencia con train)\n"
     ]
    }
   ],
   "source": [
    "print(f\"train      - {f1_score_train:.4}\")\n",
    "print(f\"validation - {f1_score_val:.4} - ({(100 - f1_score_val / f1_score_train * 100):.4}% de diferencia con train)\")\n",
    "print(f\"test       - {f1_score_test:.4} - ({(100 - f1_score_test / f1_score_train * 100):.4}% de diferencia con train)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDzVLI-MP3xI"
   },
   "source": [
    "# Predicciones sobre el dataset de testing de la competencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente hacemos las predicciones para la competencia de Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "YqqZTAQ_Xxm4",
    "outputId": "bf38886a-bb3f-4b28-d646-f6feb156e0b6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;log_loss&#x27;, max_depth=35, min_samples_leaf=16,\n",
       "                       min_samples_split=12, n_estimators=2000, n_jobs=-1,\n",
       "                       oob_score=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;log_loss&#x27;, max_depth=35, min_samples_leaf=16,\n",
       "                       min_samples_split=12, n_estimators=2000, n_jobs=-1,\n",
       "                       oob_score=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='log_loss', max_depth=35, min_samples_leaf=16,\n",
       "                       min_samples_split=12, n_estimators=2000, n_jobs=-1,\n",
       "                       oob_score=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "ct_final = copy.deepcopy(ct)\n",
    "\n",
    "X_final_trans = ct_final.fit_transform(df[feature_cols])\n",
    "y_final = df[\"sentimiento\"]\n",
    "\n",
    "rf.fit(X_final_trans, y_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7pQfI2L4Rict",
    "outputId": "f8554a6f-ab3a-4c70-ee6b-f35a98504094"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID\n",
       "60000    negativo\n",
       "60001    negativo\n",
       "60002    negativo\n",
       "60003    negativo\n",
       "60004    positivo\n",
       "           ...   \n",
       "68594    positivo\n",
       "68595    negativo\n",
       "68596    positivo\n",
       "68597    negativo\n",
       "68598    negativo\n",
       "Name: sentimiento, Length: 8599, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kaggle = pd.read_csv(\"../datasets/random-forest.zip\", index_col=0)\n",
    "df_kaggle[\"sentimiento\"] = rf.predict(ct_final.transform(df_kaggle[feature_cols]))\n",
    "df_kaggle[\"sentimiento\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZTtA_MBRxH4"
   },
   "outputs": [],
   "source": [
    "df_kaggle[\"sentimiento\"].to_csv(\"output.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
